{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c6467e7a-e6a8-421c-95bc-caf6641d3e4b",
   "metadata": {},
   "source": [
    "# Note\n",
    "\n",
    "You'll want to install `fuzzywuzzy==0.18.0`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf2a55b7-079f-43a1-bd34-7c2b3756f1e1",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'instance_1_config' from 'lib.service.database.defaults' (/Users/angus/code/jupyter/notebooks/20240907, vg/lib/service/database/defaults.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mlogging\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mservice\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatabase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DatabaseService\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mservice\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatabase\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdefaults\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m instance_1_config\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mservice\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m IoService\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtasks\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfetch_static_files\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m initialise, get_session\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'instance_1_config' from 'lib.service.database.defaults' (/Users/angus/code/jupyter/notebooks/20240907, vg/lib/service/database/defaults.py)"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "from lib.service.database import DatabaseService\n",
    "from lib.service.database.defaults import instance_1_config\n",
    "from lib.service.io import IoService\n",
    "from lib.tasks.fetch_static_files import initialise, get_session\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "io = IoService.create(None)\n",
    "\n",
    "async with get_session(io) as session:\n",
    "    environment = await initialise(io, session)\n",
    "\n",
    "db = DatabaseService(instance_1_config)\n",
    "await db.wait_till_running()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "830ee332-8aed-4bde-9449-2499e045fb65",
   "metadata": {},
   "source": [
    "## Link GNAF with land values\n",
    "\n",
    "Now for a messy part. There's a few obstacles in the way before we can link the GNAF dataset with the addresses in the NSW valuer general dataset. Here are a few\n",
    "\n",
    "- No direct identifer found in both on a property basis\n",
    "- Inconsistent street naming conventions\n",
    "- Some properties are missing fields you'd expect to use to link data `suburb` and `street_name`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3249f46f-0332-4b0e-872b-d2294cef0ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from fuzzywuzzy import fuzz\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "\n",
    "engine = db.engine()\n",
    "\n",
    "async with db.async_connect() as conn, conn.cursor() as cursor:\n",
    "    await cursor.execute(\"DROP TABLE IF EXISTS nsw_valuer_general.property_assoc\")\n",
    "    await cursor.execute(\"DROP TABLE IF EXISTS nsw_valuer_general.street_assoc\")\n",
    "    await cursor.execute(\"DROP TABLE IF EXISTS nsw_valuer_general.suburb_assoc\")\n",
    "    with open('sql/nsw_lv_schema_4_links.sql', 'r') as f:\n",
    "        await cursor.execute(f.read())\n",
    "\n",
    "suburbs_df = pd.read_sql(\"\"\"\n",
    "SELECT DISTINCT su.suburb_id, su.suburb_name, su.district_code\n",
    "  FROM nsw_valuer_general.property p\n",
    "  LEFT JOIN nsw_valuer_general.suburb su ON p.suburb_id = su.suburb_id\n",
    " ORDER BY su.suburb_name\n",
    " -- WHERE su.suburb_name = 'ADAMINABY'\n",
    "\"\"\", engine)\n",
    "\n",
    "def check_col_is_unique(df, col, msg, throw=False):\n",
    "    if df[col].is_unique:\n",
    "        return None\n",
    "        \n",
    "    indexes = df[col].duplicated(keep=False)\n",
    "    display(df[indexes])\n",
    "    print(msg % df[indexes][col].unique())\n",
    "    \n",
    "    if throw:\n",
    "        raise Exception(\"Failed unique check\")\n",
    "    else:\n",
    "        return indexes\n",
    "\n",
    "def calculate_cost_matrix(df_a, df_b):\n",
    "    cost_matrix = []\n",
    "    for _, row_a in df_a.iterrows():\n",
    "        row_costs = []\n",
    "        for _, row_b in df_b.iterrows():\n",
    "            score = 100 - fuzz.ratio(row_a['street_name'], row_b['gnaf_street_name'])\n",
    "            row_costs.append(score)\n",
    "        cost_matrix.append(row_costs)\n",
    "    \n",
    "    # Padding the cost matrix to ensure square shape\n",
    "    max_dim = max(len(df_a), len(df_b))\n",
    "    padded_cost_matrix = np.full((max_dim, max_dim), 100)  # High cost for padding\n",
    "    padded_cost_matrix[:len(df_a), :len(df_b)] = cost_matrix\n",
    "    \n",
    "    return padded_cost_matrix\n",
    "    \n",
    "unmatched_rows = []\n",
    "\n",
    "for index, suburb in suburbs_df.iterrows():\n",
    "    print(suburb['suburb_name'])\n",
    "    \n",
    "    vg_streets_df = pd.read_sql(\"\"\"\n",
    "        SELECT *\n",
    "          FROM nsw_valuer_general.street\n",
    "         WHERE suburb_id = %(suburb_id)s\n",
    "    \"\"\", engine, params={\n",
    "        \"suburb_id\": suburb['suburb_id'],\n",
    "    })\n",
    "    \n",
    "    if len(vg_streets_df) == 0:\n",
    "        print('no matches')\n",
    "        raise Exception()\n",
    "\n",
    "    postcodes = tuple(vg_streets_df['postcode'].unique())\n",
    "\n",
    "    gnaf_s_df = pd.read_sql(\"\"\"\n",
    "        SELECT DISTINCT \n",
    "            sl.street_locality_pid as gnaf_street_locality_pid,\n",
    "            sl.street_name,\n",
    "            sl.street_type_code,\n",
    "            sl.street_name \n",
    "              || COALESCE(' ' || sta.name, '')\n",
    "              || COALESCE(' ' || ssa.name, '')\n",
    "              as gnaf_street_name,\n",
    "            l.locality_name as suburb_name,\n",
    "            ad.postcode\n",
    "\n",
    "          FROM gnaf.ADDRESS_DETAIL ad\n",
    "          LEFT JOIN gnaf.locality l ON ad.locality_pid = l.locality_pid\n",
    "          LEFT JOIN gnaf.STREET_LOCALITY sl ON sl.street_locality_pid = ad.street_locality_pid\n",
    "          LEFT JOIN gnaf.STATE s ON l.state_pid = s.state_pid\n",
    "          LEFT JOIN gnaf.STREET_TYPE_AUT sta ON sta.code = sl.street_type_code\n",
    "          LEFT JOIN gnaf.STREET_SUFFIX_AUT ssa ON ssa.code = sl.street_suffix_code\n",
    "          \n",
    "         WHERE l.locality_name = %(suburb_name)s\n",
    "           AND ad.postcode IN %(postcodes)s\n",
    "           AND s.state_abbreviation = 'NSW'\n",
    "    \"\"\", engine, params={\n",
    "        \"suburb_name\": suburb['suburb_name'],\n",
    "        \"postcodes\": postcodes,\n",
    "    })\n",
    "\n",
    "    for postcode in postcodes:\n",
    "        v_slice = vg_streets_df[vg_streets_df['postcode'] == postcode].reset_index(drop=True)\n",
    "        g_slice = gnaf_s_df[gnaf_s_df['postcode'] == postcode].reset_index(drop=True)\n",
    "        \n",
    "        check_col_is_unique(g_slice,\n",
    "                            'gnaf_street_name',\n",
    "                            f\"{suburb['suburb_name']} non unique streets %s\",\n",
    "                            throw=True)\n",
    "        \n",
    "        if len(g_slice) == 0:\n",
    "            unmatched_rows.append(v_slice)\n",
    "            continue\n",
    "        \n",
    "        cost_matrix = calculate_cost_matrix(v_slice, g_slice)\n",
    "        row_ind, col_ind = linear_sum_assignment(cost_matrix)\n",
    "    \n",
    "        v_slice['gnaf_street_name'] = [\n",
    "            g_slice.iloc[col]['gnaf_street_name'] if col < len(gnaf_s_df) else None\n",
    "            for col in col_ind[:len(v_slice)]\n",
    "        ]\n",
    "        v_slice['gnaf_street_name_cost'] = [\n",
    "            cost_matrix[idx, col_idx]\n",
    "            for idx, col_idx in enumerate(col_ind[:len(v_slice)])\n",
    "        ]\n",
    "\n",
    "        v_slice['drop'] = False\n",
    "        v_slice.loc[v_slice['gnaf_street_name'].isna(), 'drop'] = True\n",
    "        v_slice.loc[v_slice['gnaf_street_name_cost'] > 20, 'drop'] = True\n",
    "\n",
    "        if not v_slice[v_slice['drop']].empty:\n",
    "            unmatched = v_slice[v_slice['drop']]\n",
    "            display(unmatched[['street_name', 'gnaf_street_name', 'gnaf_street_name_cost']])\n",
    "            unmatched_rows.append(unmatched)\n",
    "            \n",
    "        display(v_slice[~v_slice['drop']])\n",
    "        \n",
    "        v_slice = v_slice[~v_slice['drop']]\\\n",
    "            .merge(g_slice, how='left', on=['gnaf_street_name', 'postcode'])\n",
    "        \n",
    "        street_assoc_df = v_slice[['street_id', 'gnaf_street_locality_pid']]\n",
    "        street_assoc_df.to_sql('street_assoc',\n",
    "                               engine,\n",
    "                               schema='nsw_valuer_general',\n",
    "                               if_exists='append',\n",
    "                               index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a9a96a2-7e05-4e3e-b30f-a5f7032b2f3d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
