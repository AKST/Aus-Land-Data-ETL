{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e64a6769-685f-4029-8daa-4780d096ef81",
   "metadata": {},
   "source": [
    "# Dataset ingestion\n",
    "\n",
    "This jupyter noteebook ingests the [Geocoded National Address File][gnaf] ([GNAF][gnaf]) from [data.gov.au](data.gov.au). It also downloads the [land values for NSW][nswlv], and ABS shapefiles \n",
    "\n",
    "It loads it all this data into a PostgreSQL database in a docker container, treating it like a disposable sqlite data store. It also downloads the ABS shape files as well as the \n",
    "\n",
    "Here we are going to ingest all the data necessary in order to assess land by land values, and filter them by address information. \n",
    "\n",
    "### The Steps\n",
    "\n",
    "1. Download static assets and datasets\n",
    "2. Setup a docker container with postgresql with GIS capabilities.\n",
    "3. Ingest the [ABS shape files][abssf]\n",
    "4. Ingest the latest [NSW valuer general land values][nswlv].\n",
    "5. Ingest the [Geocoded National Address File][gnaf] ([GNAF][gnaf]) dataset\n",
    "6. Link NSW Valuer General data with GNAF dataset\n",
    "\n",
    "[gnaf]: https://data.gov.au/data/dataset/geocoded-national-address-file-g-naf\n",
    "[nswlv]: https://www.valuergeneral.nsw.gov.au/land_value_summaries/lv.php\n",
    "[abssf]: https://www.abs.gov.au/statistics/standards/australian-statistical-geography-standard-asgs-edition-3/jul2021-jun2026/access-and-downloads/digital-boundary-files\n",
    "\n",
    "### Note\n",
    "\n",
    "- Make sure docker is running first.\n",
    "\n",
    "### Warning\n",
    "\n",
    "Do not connect this to another database unless you've taken the time to update this, as it'll drop the existing database. I suggest instead take what you need from this script and disregard the rest. DO NOT USE DATABASE CREDENTIALS HERE FOR ANY OTHER STORE (especailly anything with drop permissions).\n",
    "\n",
    "It also executes sql from a zip file downloaded from an external source.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a77f1d8-22ff-4aa2-8740-58dd6b05c461",
   "metadata": {},
   "source": [
    "## Configuration\n",
    "\n",
    "These are some fields to configure if you wish to configure how the data is injected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ab987146-dde7-4ddc-bd9c-916596d4badb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib.service.docker.defaults import INSTANCE_1_IMAGE_CONF, INSTANCE_1_CONTAINER_CONF\n",
    "from lib.service.database.defaults import DB_INSTANCE_1_CONFIG\n",
    "\n",
    "GLOBAL_FLAGS = {\n",
    "    # If you mark this as true, the table `nsw_valuer_general.raw_entries`\n",
    "    # will be dropped. If you have space limitations and no desire to debug\n",
    "    # the data than dropping this makes sense. If you wish to debug some values\n",
    "    # then keeping this around may make some sense.\n",
    "    'drop_raw_nsw_valuer_general_entries': True,\n",
    "    'reinitialise_container': True,\n",
    "}\n",
    "\n",
    "db_service_config = DB_INSTANCE_1_CONFIG\n",
    "docker_image_conf = INSTANCE_1_IMAGE_CONF\n",
    "docker_container_conf = INSTANCE_1_CONTAINER_CONF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48db8607-3ea8-43c1-9b87-3af22555c2b4",
   "metadata": {},
   "source": [
    "## Steps\n",
    "\n",
    "### Download Static Files\n",
    "\n",
    "First we'll download all the static files. This has been setup to minimise network activity. This is done by:\n",
    "\n",
    "1. Not fetching files that already on disk.\n",
    "2. Any HTML that is scrapped to find links is also cached. This isn't really any more than a week.\n",
    "\n",
    "This means this entire process can be run offline once run online successfully.\n",
    "\n",
    "### Initialise Docker Container\n",
    "\n",
    "> Note: If it doesn't go without saying, rerunning this will basically nuke any changes you've made to the schema.\n",
    "\n",
    "Next we create a docker image and container, uses the constants `docker_image_conf` and `docker_container_conf`. The\n",
    "image we're creating is defined in `./config/dockerfiles`, it's basically the latest official `postgres` that runs on\n",
    "apple silicon, along with extensions for `GIS` (as of October 28th). It does the following steps:\n",
    "\n",
    "1. Nuke any container that matches the one specfied in `docker_container_conf`, _if it exists_.\n",
    "2. If the image specified in `docker_image_conf` doesn't already exists create it.\n",
    "3. Create a new container using that image.\n",
    "4. Await for the database to start accepting connections before proceeding.\n",
    "\n",
    "\n",
    "### Initalise the schema\n",
    "\n",
    "You can do this step in CLI by running the following\n",
    "\n",
    "```\n",
    "python -m lib.tasks.schema.update --packages meta,abs,nsw_gnb,nsw_lrs,nsw_planning,nsw_vg --instance 1\n",
    "```\n",
    "\n",
    "What are the different symbols seperated by comma? Those \"packages\" are just directories in `./sql` most\n",
    "of which have one schema, however some of these have multiple mostly for staging prior to processing. For\n",
    "the latest description of the different packages I would suggest jumping to `./sql/README.md` and read\n",
    "through the different descriptions of the different subdirectories.\n",
    "\n",
    "Basically tho, the database schema tries place data in a schema closest to the government agency that is\n",
    "actually responsible for maintaining that data, even if that data didn't come from them directory. The\n",
    "main motivation behind that is to have a single place for repeating data and that made sense to me.\n",
    "\n",
    "### Consume the ABS Shapefiles\n",
    "\n",
    "You can do this in CLI by running the following\n",
    "\n",
    "```\n",
    "python -m lib.tasks.ingest_abs --instance 1 --workers 4\n",
    "```\n",
    "\n",
    "The [ABS provides a number of shape files][all abs shape files], we're going focus on 2 main sets of shapes. The **ABS Main Structures** which is stuff like SA1, 2, 3 & 4 along with greater cities, meshblocks, and states. As well as **Non ABS Main Structures** which is stuff like electoral divisions, suburbs post codes etc.\n",
    "\n",
    "[all abs shape files]: https://www.abs.gov.au/statistics/standards/australian-statistical-geography-standard-asgs-edition-3/jul2021-jun2026/access-and-downloads/digital-boundary-files\n",
    "\n",
    "#### ABS Main Structures \n",
    "\n",
    "Any address or region we look up in the GNAF dataset, we want to visualise. The ABS has a few different geographic groups which we can visualise the data against, but each address in the GNAF dataset has a meshblock id, which is the smaller block the ABS breaks addresses up into for SA1, SA2, SA3 and SA4's.\n",
    "\n",
    "This dataset is pretty useful for visualising the GNAF data for that reason.\n",
    "\n",
    "#### Non Abs Main Structures \n",
    "\n",
    "We are mostly ingesting these to make it simpler to narrow data of interest. Typically if you're looking at this data, you're probably doing it some scope of relevance, such as a local government area, an electorate division, or whatever.\n",
    "\n",
    "### Ingesting NSW Land Values & PSI\n",
    "\n",
    "Next to ingest the NSW land values and Property sales data.\n",
    "\n",
    "#### Documentation on this dataset\n",
    "\n",
    "The valuer general website has a link to documentation on interpretting that data on [this page](https://www.nsw.gov.au/housing-and-construction/land-values-nsw/resource-library/land-value-information-user-guide). I didn't link to the PDF directly as it occasionally updated and a direct link is at risk of going stale.\n",
    "\n",
    "It's useful getting the meaning behind the codes and terms used in the bulk data.\n",
    "\n",
    "#### Steps\n",
    "\n",
    "1. **Build the `nsw_valuer_general.raw_entries_lv` table**: Here we are\n",
    "   just loading the each file from the latest land value publication\n",
    "   with minimal changes, and a bit of sanitisizing.\n",
    "2. **Break CSV data into sepreate relations**, Just to break up the data\n",
    "   into more efficent representations of the data, and data that will be\n",
    "   easier to query, we're going to perform a series of queries against\n",
    "   the GNAF data before using it populate the tables we care about.\n",
    "3. **Parse contents of the property description**, The `property_description`\n",
    "   from the original valuer general data constains alot of information. The\n",
    "   most important of which is the land parcel or `lot/plan` information.\n",
    "   There is other information in there as well.\n",
    "4. If specified drop the raw entries consumed in step (tho the default is\n",
    "   to do exactly that. \n",
    "\n",
    "### Gnaf Ingestion\n",
    "\n",
    "Here we ingest the GNAF dataset, this will take awhile."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecdc9d00-5480-4cc8-a382-7eb6e649469d",
   "metadata": {},
   "source": [
    "## Running Everything\n",
    "\n",
    "All of the above has been moved to this command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "320cd7fe-f03d-4230-9e0f-a2ef302a91b2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-28 10:11:21,232 - INFO - Checking Target \"abs_main_structures.zip\"\n",
      "2024-10-28 10:11:21,233 - INFO - Checking Target \"non_abs_shape.zip\"\n",
      "2024-10-28 10:11:21,233 - INFO - Checking Target \"g-naf_aug24_allstates_gda2020_psv_1016.zip\"\n",
      "2024-10-28 10:11:21,233 - INFO - Checking Target \"nswvg_lv_01_Oct_2024.zip\"\n",
      "2024-10-28 10:11:21,234 - INFO - Checking Target \"nswvg_wps_01_Jan_2024.zip\"\n",
      "2024-10-28 10:11:21,235 - INFO - Checking Target \"nswvg_wps_08_Jan_2024.zip\"\n",
      "2024-10-28 10:11:21,235 - INFO - Checking Target \"nswvg_wps_15_Jan_2024.zip\"\n",
      "2024-10-28 10:11:21,235 - INFO - Checking Target \"nswvg_wps_22_Jan_2024.zip\"\n",
      "2024-10-28 10:11:21,236 - INFO - Checking Target \"nswvg_wps_29_Jan_2024.zip\"\n",
      "2024-10-28 10:11:21,236 - INFO - Checking Target \"nswvg_wps_05_Feb_2024.zip\"\n",
      "2024-10-28 10:11:21,236 - INFO - Checking Target \"nswvg_wps_12_Feb_2024.zip\"\n",
      "2024-10-28 10:11:21,236 - INFO - Checking Target \"nswvg_wps_19_Feb_2024.zip\"\n",
      "2024-10-28 10:11:21,237 - INFO - Checking Target \"nswvg_wps_26_Feb_2024.zip\"\n",
      "2024-10-28 10:11:21,237 - INFO - Checking Target \"nswvg_wps_04_Mar_2024.zip\"\n",
      "2024-10-28 10:11:21,237 - INFO - Checking Target \"nswvg_wps_11_Mar_2024.zip\"\n",
      "2024-10-28 10:11:21,238 - INFO - Checking Target \"nswvg_wps_18_Mar_2024.zip\"\n",
      "2024-10-28 10:11:21,238 - INFO - Checking Target \"nswvg_wps_25_Mar_2024.zip\"\n",
      "2024-10-28 10:11:21,238 - INFO - Checking Target \"nswvg_wps_01_Apr_2024.zip\"\n",
      "2024-10-28 10:11:21,238 - INFO - Checking Target \"nswvg_wps_08_Apr_2024.zip\"\n",
      "2024-10-28 10:11:21,239 - INFO - Checking Target \"nswvg_wps_15_Apr_2024.zip\"\n",
      "2024-10-28 10:11:21,239 - INFO - Checking Target \"nswvg_wps_22_Apr_2024.zip\"\n",
      "2024-10-28 10:11:21,239 - INFO - Checking Target \"nswvg_wps_29_Apr_2024.zip\"\n",
      "2024-10-28 10:11:21,239 - INFO - Checking Target \"nswvg_wps_06_May_2024.zip\"\n",
      "2024-10-28 10:11:21,240 - INFO - Checking Target \"nswvg_wps_13_May_2024.zip\"\n",
      "2024-10-28 10:11:21,240 - INFO - Checking Target \"nswvg_wps_20_May_2024.zip\"\n",
      "2024-10-28 10:11:21,240 - INFO - Checking Target \"nswvg_wps_27_May_2024.zip\"\n",
      "2024-10-28 10:11:21,241 - INFO - Checking Target \"nswvg_wps_03_Jun_2024.zip\"\n",
      "2024-10-28 10:11:21,241 - INFO - Checking Target \"nswvg_wps_10_Jun_2024.zip\"\n",
      "2024-10-28 10:11:21,241 - INFO - Checking Target \"nswvg_wps_17_Jun_2024.zip\"\n",
      "2024-10-28 10:11:21,241 - INFO - Checking Target \"nswvg_wps_24_Jun_2024.zip\"\n",
      "2024-10-28 10:11:21,241 - INFO - Checking Target \"nswvg_wps_01_Jul_2024.zip\"\n",
      "2024-10-28 10:11:21,242 - INFO - Checking Target \"nswvg_wps_08_Jul_2024.zip\"\n",
      "2024-10-28 10:11:21,242 - INFO - Checking Target \"nswvg_wps_15_Jul_2024.zip\"\n",
      "2024-10-28 10:11:21,242 - INFO - Checking Target \"nswvg_wps_22_Jul_2024.zip\"\n",
      "2024-10-28 10:11:21,243 - INFO - Checking Target \"nswvg_wps_29_Jul_2024.zip\"\n",
      "2024-10-28 10:11:21,243 - INFO - Checking Target \"nswvg_wps_05_Aug_2024.zip\"\n",
      "2024-10-28 10:11:21,243 - INFO - Checking Target \"nswvg_wps_12_Aug_2024.zip\"\n",
      "2024-10-28 10:11:21,243 - INFO - Checking Target \"nswvg_wps_19_Aug_2024.zip\"\n",
      "2024-10-28 10:11:21,244 - INFO - Checking Target \"nswvg_wps_26_Aug_2024.zip\"\n",
      "2024-10-28 10:11:21,244 - INFO - Checking Target \"nswvg_wps_02_Sep_2024.zip\"\n",
      "2024-10-28 10:11:21,244 - INFO - Checking Target \"nswvg_wps_09_Sep_2024.zip\"\n",
      "2024-10-28 10:11:21,244 - INFO - Checking Target \"nswvg_wps_16_Sep_2024.zip\"\n",
      "2024-10-28 10:11:21,245 - INFO - Checking Target \"nswvg_wps_23_Sep_2024.zip\"\n",
      "2024-10-28 10:11:21,245 - INFO - Checking Target \"nswvg_wps_30_Sep_2024.zip\"\n",
      "2024-10-28 10:11:21,245 - INFO - Checking Target \"nswvg_wps_07_Oct_2024.zip\"\n",
      "2024-10-28 10:11:21,245 - INFO - Checking Target \"nswvg_wps_14_Oct_2024.zip\"\n",
      "2024-10-28 10:11:21,246 - INFO - Checking Target \"nswvg_wps_21_Oct_2024.zip\"\n",
      "2024-10-28 10:11:21,246 - INFO - Checking Target \"nswvg_wps_28_Oct_2024.zip\"\n",
      "2024-10-28 10:11:21,246 - INFO - Checking Target \"nswvg_aps_1990.zip\"\n",
      "2024-10-28 10:11:21,247 - INFO - Checking Target \"nswvg_aps_1991.zip\"\n",
      "2024-10-28 10:11:21,247 - INFO - Checking Target \"nswvg_aps_1992.zip\"\n",
      "2024-10-28 10:11:21,247 - INFO - Checking Target \"nswvg_aps_1993.zip\"\n",
      "2024-10-28 10:11:21,248 - INFO - Checking Target \"nswvg_aps_1994.zip\"\n",
      "2024-10-28 10:11:21,248 - INFO - Checking Target \"nswvg_aps_1995.zip\"\n",
      "2024-10-28 10:11:21,248 - INFO - Checking Target \"nswvg_aps_1996.zip\"\n",
      "2024-10-28 10:11:21,249 - INFO - Checking Target \"nswvg_aps_1997.zip\"\n",
      "2024-10-28 10:11:21,249 - INFO - Checking Target \"nswvg_aps_1998.zip\"\n",
      "2024-10-28 10:11:21,249 - INFO - Checking Target \"nswvg_aps_1999.zip\"\n",
      "2024-10-28 10:11:21,250 - INFO - Checking Target \"nswvg_aps_2000.zip\"\n",
      "2024-10-28 10:11:21,250 - INFO - Checking Target \"nswvg_aps_2001.zip\"\n",
      "2024-10-28 10:11:21,251 - INFO - Checking Target \"nswvg_aps_2002.zip\"\n",
      "2024-10-28 10:11:21,251 - INFO - Checking Target \"nswvg_aps_2003.zip\"\n",
      "2024-10-28 10:11:21,252 - INFO - Checking Target \"nswvg_aps_2004.zip\"\n",
      "2024-10-28 10:11:21,252 - INFO - Checking Target \"nswvg_aps_2005.zip\"\n",
      "2024-10-28 10:11:21,252 - INFO - Checking Target \"nswvg_aps_2006.zip\"\n",
      "2024-10-28 10:11:21,253 - INFO - Checking Target \"nswvg_aps_2007.zip\"\n",
      "2024-10-28 10:11:21,253 - INFO - Checking Target \"nswvg_aps_2008.zip\"\n",
      "2024-10-28 10:11:21,253 - INFO - Checking Target \"nswvg_aps_2009.zip\"\n",
      "2024-10-28 10:11:21,254 - INFO - Checking Target \"nswvg_aps_2010.zip\"\n",
      "2024-10-28 10:11:21,254 - INFO - Checking Target \"nswvg_aps_2011.zip\"\n",
      "2024-10-28 10:11:21,254 - INFO - Checking Target \"nswvg_aps_2012.zip\"\n",
      "2024-10-28 10:11:21,255 - INFO - Checking Target \"nswvg_aps_2013.zip\"\n",
      "2024-10-28 10:11:21,255 - INFO - Checking Target \"nswvg_aps_2014.zip\"\n",
      "2024-10-28 10:11:21,255 - INFO - Checking Target \"nswvg_aps_2015.zip\"\n",
      "2024-10-28 10:11:21,256 - INFO - Checking Target \"nswvg_aps_2016.zip\"\n",
      "2024-10-28 10:11:21,256 - INFO - Checking Target \"nswvg_aps_2017.zip\"\n",
      "2024-10-28 10:11:21,256 - INFO - Checking Target \"nswvg_aps_2018.zip\"\n",
      "2024-10-28 10:11:21,257 - INFO - Checking Target \"nswvg_aps_2019.zip\"\n",
      "2024-10-28 10:11:21,257 - INFO - Checking Target \"nswvg_aps_2020.zip\"\n",
      "2024-10-28 10:11:21,257 - INFO - Checking Target \"nswvg_aps_2021.zip\"\n",
      "2024-10-28 10:11:21,258 - INFO - Checking Target \"nswvg_aps_2022.zip\"\n",
      "2024-10-28 10:11:21,258 - INFO - Checking Target \"nswvg_aps_2023.zip\"\n"
     ]
    }
   ],
   "source": [
    "from lib.tasks.ingest import ingest_all, IngestConfig\n",
    "\n",
    "config = IngestConfig(\n",
    "    io_file_limit=None,\n",
    "    db_config=db_service_config,\n",
    "    docker_image_config=docker_image_conf,\n",
    "    docker_container_config=docker_container_conf\n",
    ")\n",
    "\n",
    "await ingest_all(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e9d765d-beb1-4aab-a220-5fa5fee84aa2",
   "metadata": {},
   "source": [
    "## In CLI\n",
    "\n",
    "Note you can do all this in CLI as well running the following:\n",
    "\n",
    "```sh\n",
    "python -m lib.tasks.ingest --instance 1\n",
    "```\n",
    "\n",
    "As of writing this, there's only 2 instances. The reason for more than one is too allow for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fadf67b8-91d4-44e0-82e3-938fde506451",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
